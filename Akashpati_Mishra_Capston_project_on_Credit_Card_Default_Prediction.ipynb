{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKASHPATI007/Credit-Card-Default-Prediction/blob/main/Akashpati_Mishra_Capston_project_on_Credit_Card_Default_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name   -  Predicting whether a customer will default on his/her credit card**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification-Credit Card Default Prediction\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   We are all aware what is credit card. It is type of payment payment card in which charges are made against a line of credit instead of the account holder's cash deposits. When someone uses a credit card to make a purchase, that person's account accrues a balance that must be paid off each month.\n",
        "\n",
        "2.   Credit card default happens when you have become severely delinquent on your credit card payments.Missing credit card payments once or twice does not count as a default. A payment default occurs when you fail to pay the Minimum Amount Due on the credit card for a few consecutive months.\n",
        "\n",
        "3.   It is the peolpe who do not clear off the credit card debt aka credit card defaulters.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VNXsVCS9uA0w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37V4oqYhuAAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/AKASHPATI007"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This project is aimed at predicting the case of customers' default payments in Taiwan. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. We can use the KS chart to evaluate which customers will default on their credit card payments.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "\n",
        "   This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:\n",
        "\n",
        "1.   X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
        "\n",
        "2.   X2: Gender (1 = male; 2 = female).\n",
        "\n",
        "3.   X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
        "\n",
        "4.   X4: Marital status (1 = married; 2 = single; 3 = others).\n",
        "\n",
        "5.   X5: Age (year).\n",
        "\n",
        "\n",
        "6.   X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows:\n",
        "\n",
        "7.    X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
        "\n",
        "8.   X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
        "\n",
        "9.   X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4XV6BXo2TBp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business Objective**"
      ],
      "metadata": {
        "id": "xAlFUzONwDsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Objective of our project is to predict which customer might default in upcoming months. Before going any further let's have a quick look on definition of what actually meant by Credit Card Default.\n",
        "\n",
        "2.   The research aims at developing a mechanism to predict the credit card default beforehand and to identify the potential customer base that can be offered various credit instruments so as to invite minimum default.\n",
        "\n"
      ],
      "metadata": {
        "id": "dPPZkv0mwKF-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8soOGh_JxduK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "#SMOTE for handling class imbalance\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score,roc_auc_score,recall_score,f1_score\n",
        "from sklearn.model_selection import cross_validate,cross_val_score\n",
        "\n",
        "\n",
        "# This will ignore all the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oj0ubHK1GImL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/almabetter/project/credit card default pred/default of credit card clients (1).xls\")"
      ],
      "metadata": {
        "id": "bTqXtXY8GT3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().values.any()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "missing = pd.DataFrame((df.isnull().sum())*100/df.shape[0]).reset_index()\n",
        "plt.figure(figsize=(16,5))\n",
        "ax = sns.pointplot('index',0,data=missing)\n",
        "plt.xticks(rotation =90,fontsize =7)\n",
        "plt.title(\"Percentage of Missing values\")\n",
        "plt.ylabel(\"PERCENTAGE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Datasets contains 30001 rows and 25 columns.\n",
        "There is no null values.\n",
        "There is no duplicate values.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all').T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Processing**"
      ],
      "metadata": {
        "id": "iOACik2jwfbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing the name from 0 to 1 in order to maintain the sequence \n",
        "df.rename(columns={'PAY_0':'PAY_1'},inplace=True) "
      ],
      "metadata": {
        "id": "VTez6O6fwacF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "BuwQFaF_caaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['EDUCATION'].value_counts()"
      ],
      "metadata": {
        "id": "wACQmJSmdVa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in our attribute only 1,2,3,4 are present so add all data of 5, 6 & 0 to 4."
      ],
      "metadata": {
        "id": "7ZFFVL294d20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning Education\n",
        "fil = (df['EDUCATION'] == 5) | (df['EDUCATION'] == 6) | (df['EDUCATION'] == 0)\n",
        "df.loc[fil, 'EDUCATION'] = 4\n"
      ],
      "metadata": {
        "id": "jp5WyDsXwoA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['EDUCATION'].value_counts()"
      ],
      "metadata": {
        "id": "708ib1Im0NZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W2cBIlLC40J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['MARRIAGE'].value_counts()"
      ],
      "metadata": {
        "id": "MBrxkt8TduFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In attribute data only 1,2,3 present so add 0 to 3 in other category."
      ],
      "metadata": {
        "id": "EPL6TeEp44Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning Marriage\n",
        "fil = df['MARRIAGE'] == 0\n",
        "df.loc[fil, 'MARRIAGE'] = 3"
      ],
      "metadata": {
        "id": "VSMMAwZNwn87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the name for better readability\n",
        "df.rename(columns={'PAY_1':'PAY_SEPT','PAY_2':'PAY_AUG','PAY_3':'PAY_JUL','PAY_4':'PAY_JUN','PAY_5':'PAY_MAY','PAY_6':'PAY_APR'},inplace=True)\n",
        "df.rename(columns={'BILL_AMT1':'BILL_AMT_SEPT','BILL_AMT2':'BILL_AMT_AUG','BILL_AMT3':'BILL_AMT_JUL','BILL_AMT4':'BILL_AMT_JUN','BILL_AMT5':'BILL_AMT_MAY','BILL_AMT6':'BILL_AMT_APR'}, inplace = True)\n",
        "df.rename(columns={'PAY_AMT1':'PAY_AMT_SEPT','PAY_AMT2':'PAY_AMT_AUG','PAY_AMT3':'PAY_AMT_JUL','PAY_AMT4':'PAY_AMT_JUN','PAY_AMT5':'PAY_AMT_MAY','PAY_AMT6':'PAY_AMT_APR'},inplace=True)"
      ],
      "metadata": {
        "id": "V4n-hCijwnz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Outliers**"
      ],
      "metadata": {
        "id": "7o1ERjUbxwWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the number of rows and columns before outlier treatment\n",
        "print('\\033[1mBefore Outlier Treatment\\033[0m')\n",
        "print('Number of rows: {}\\nNumber of columns:{}'.format(df.shape[0],df.shape[1]))"
      ],
      "metadata": {
        "id": "gNCrgTe9wnsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "sEqFTUAXx3VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Box plots to check outliers\n",
        "\n",
        "lst_box = df[[ 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_SEPT',\n",
        "       'PAY_AUG', 'PAY_JUL', 'PAY_JUN', 'PAY_MAY', 'PAY_APR', 'BILL_AMT_SEPT',\n",
        "       'BILL_AMT_AUG', 'BILL_AMT_JUL', 'BILL_AMT_JUN', 'BILL_AMT_MAY',\n",
        "       'BILL_AMT_APR', 'PAY_AMT_SEPT', 'PAY_AMT_AUG', 'PAY_AMT_JUL',\n",
        "       'PAY_AMT_JUN', 'PAY_AMT_MAY', 'PAY_AMT_APR']]\n",
        "\n",
        "# Box plot to detect outliers\n",
        "plt.figure(figsize = (70,150))\n",
        "sns.set_theme()\n",
        "for i in enumerate(lst_box):\n",
        "  plt.subplot(12, 2, i[0]+1)\n",
        "  sns.set(font_scale = 2)\n",
        "  sns.boxplot(df[i[1]],color='red')\n",
        "  plt.xlabel(i[1], fontsize=40)\n",
        "sns.reset_orig()"
      ],
      "metadata": {
        "id": "89zu1CnQx3P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.PAY_SEPT.value_counts()"
      ],
      "metadata": {
        "id": "K1wrt-u1bnUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treating Pay Columns\n",
        "# Since 90 percent of our PAY data lies between -2 and 1 we will remove rest of the observations\n",
        "df = df[(df.PAY_SEPT < 2) & (df.PAY_AUG < 2) & (df.PAY_JUL < 2) & (df.PAY_JUN < 2) & (df.PAY_MAY < 2)  & (df.PAY_MAY < 2) & (df.PAY_APR < 2)]\n",
        "\n"
      ],
      "metadata": {
        "id": "dD2ZemAzx3L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treating Limit Balance\n",
        "# Removing outliers using z score method on Limit Balance column.\n",
        "df['Z_LIMIT_BAL'] = np.abs(stats.zscore(df['LIMIT_BAL']))\n",
        "df = df[(df['Z_LIMIT_BAL'] < 3)]\n",
        "df.drop(['Z_LIMIT_BAL'],axis=1,inplace=True)\n",
        "\n",
        "# Treating Age Column\n",
        "df=df[(df.AGE)<61]\n",
        "\n"
      ],
      "metadata": {
        "id": "eKZILQXjx3Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "QI6GMYAIzIb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst_box = df[['PAY_SEPT','PAY_AUG','PAY_JUL','PAY_JUN','PAY_MAY','PAY_APR','LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE']]\n",
        "# Box plot to detect outliers\n",
        "plt.figure(figsize = (70,100))\n",
        "# sns.set_theme()\n",
        "for i in enumerate(lst_box):\n",
        "  plt.subplot(10, 2, i[0]+1)\n",
        "#   sns.set(font_scale = 2)\n",
        "  sns.boxplot(df[i[1]],color='red' )\n",
        "  plt.xlabel(i[1], fontsize=40)\n",
        "\n",
        "sns.reset_orig()"
      ],
      "metadata": {
        "id": "FOrDCk4Xx3Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the box plot of BILL_AMT and PAY_AMT shows that most of the data belongs outside of 4th quartile removing outliers is not feasible \n",
        "# to remove outliers from them\n",
        "print('\\033[1mAfter Outlier Treatment\\033[0m')\n",
        "print('Number of rows   :{}\\nNumber of columns:{}'.format(df.shape[0],df.shape[1]))"
      ],
      "metadata": {
        "id": "LeVgWOfmx3Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPLORATORY DATA ANALYSIS**"
      ],
      "metadata": {
        "id": "b3ZkVWIPyukU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking values in dependent variable\n",
        "df['default payment next month'].value_counts()"
      ],
      "metadata": {
        "id": "GtLmQnT5x27R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting values in dependent variable\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(1,1,1)\n",
        "ax=sns.countplot(df['default payment next month'])\n",
        "plt.xticks(rotation=45,ticks=range(2),labels=['No','Yes'])\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
        "\n"
      ],
      "metadata": {
        "id": "SUtxZjXRx24d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of people who will default their payment is much less than number of people of people who will pay on time"
      ],
      "metadata": {
        "id": "dY1fbKv9m0Nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default payment next month\n",
        "plt.figure(figsize = (16,10))\n",
        "plt.pie(df['default payment next month'].value_counts(),radius=1,autopct='%1.0f%%', pctdistance=0.56,textprops={'fontsize': 13},labels=['Non-Defaulters','Defaulters'],explode = [0.1, 0],\n",
        "        shadow=True)\n",
        "plt.title('Defaulters to Not Defaulters',fontdict={'size':13})\n"
      ],
      "metadata": {
        "id": "XRPKHc9Qx21e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sex\n",
        "plt.figure(figsize = (16,10))\n",
        "\n",
        "ax=sns.countplot(df['SEX'])\n",
        "plt.xticks(rotation=0,ticks=range(2),labels=['Male','Female'])\n",
        "plt.xlabel('SEX',fontdict={'size':13})\n",
        "for p in ax.patches:\n",
        "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
      ],
      "metadata": {
        "id": "GUU3DIm4m7OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Number of females are much more than males in our dataset."
      ],
      "metadata": {
        "id": "WcvQ_AlHnAEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "uoGpNXeizMZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "ax= sns.countplot(df['EDUCATION'])\n",
        "plt.xticks(rotation=0,ticks=range(4),labels=(['graduate school','university','high school','other']))\n",
        "plt.xlabel('EDUCATION',fontdict={'size':13})\n",
        "for p in ax.patches:\n",
        "  ax.annotate('{:.0f}'.format(p.get_height()),(p.get_x()+.025,p.get_height()+.25))"
      ],
      "metadata": {
        "id": "a7Z1bTk0zA2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Education (1 = graduate school; 2 = university; 3 = high school)\n",
        "2. As we see data for university data is higher which is 9647"
      ],
      "metadata": {
        "id": "fjEsiVblznmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.countplot(df['MARRIAGE'])\n",
        "plt.xticks(rotation=0,ticks=range(3),labels=(['married', 'single','others']))\n",
        "plt.xlabel('MARRIAGE',fontdict={'size':13})\n",
        "for p in ax.patches:\n",
        "  ax.annotate('{:.0f}'.format(p.get_height()),(p.get_x()+.25,p.get_height()+.25))\n"
      ],
      "metadata": {
        "id": "Uj9b98BL3O6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Marital status (1 = married; 2 = single; 3 = others).\n",
        "\n",
        "\n",
        "*   As we see single data is higher than other data.\n"
      ],
      "metadata": {
        "id": "RBAUGroN3vq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#AGE\n",
        "plt.figure(figsize=(15,7))\n",
        "sns.countplot(x = 'AGE', data = df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Wnvs0FbvojI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#plotting the cat plot to vizualize the data distribution related to the default_payment_next_month\n",
        "x,y = 'SEX', 'default payment next month'\n",
        "\n",
        "(df.groupby(x)[y].value_counts(normalize=True).mul(100).rename('percent').reset_index().pipe((sns.catplot,'data'), x=x,y='percent',hue=y,kind='bar'))\n",
        "\n",
        "plt.xticks(rotation=0,ticks=range(2),labels=(['male','female']))"
      ],
      "metadata": {
        "id": "OlwoybNTnU9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-male, 2-female\n",
        "\n",
        "\n",
        "*   we can also say that females tend to pay their default on time compared to their male counterparts\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q8i-SX12nPn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the cat plot to vizualize the data distribution related to the default_payment_next_month\n",
        "x,y = 'EDUCATION', 'default payment next month'\n",
        "\n",
        "(df\n",
        ".groupby(x)[y]\n",
        ".value_counts(normalize=True)\n",
        ".mul(100)\n",
        ".rename('percent')\n",
        ".reset_index()\n",
        ".pipe((sns.catplot,'data'), x=x,y='percent',hue=y,kind='bar'))\n",
        "\n",
        "plt.xticks(rotation=0,ticks=range(4),labels=(['graduate school','university','high school','other']))"
      ],
      "metadata": {
        "id": "fPww6px-zrpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plot it is clear that those people who are other students have higher default payment wrt graduates and university people"
      ],
      "metadata": {
        "id": "udKgb_a40GME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the cat plot to vizualize the data distribution related to the default_payment_next_month\n",
        "x,y = 'MARRIAGE', 'default payment next month'\n",
        "\n",
        "(df.groupby(x)[y].value_counts(normalize=True).rename('percent').reset_index().pipe((sns.catplot,'data'), x=x,y='percent',hue=y,kind='bar'))\n",
        "\n",
        "plt.xticks(rotation=0,ticks=range(3),labels=(['married', 'single','others']))"
      ],
      "metadata": {
        "id": "D14Pf0Jo0FIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see single were defaulting more than married and others."
      ],
      "metadata": {
        "id": "iaRM18w0eUN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the bar plot to vizualize the data distribution of age related to the default_payment_next_month\n",
        "plt.figure(figsize=(19,7))\n",
        "sns.barplot(x = 'AGE', y = 'default payment next month', data = df)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lKv1XpoK0kf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see from graph from age group 22 to 30 default payment is decreasing and but between age group 31 to 56 it's increasing and again 57-59 it's decreasing."
      ],
      "metadata": {
        "id": "jIerNpNPf7i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking correlation between BILL_AMT Columns\n",
        "sns.pairplot(data = df[['BILL_AMT_SEPT','BILL_AMT_AUG','BILL_AMT_JUL','BILL_AMT_JUN','BILL_AMT_MAY','BILL_AMT_APR']])"
      ],
      "metadata": {
        "id": "Z_PTCXL6x2x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From pairplot 1 Bill amount for each month is highly correlated with each other hence we will try to feature engineer bill amount to Dues column to reduce multicollinearity."
      ],
      "metadata": {
        "id": "yoYCOP8ad96y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking correlation between PAY_AMT Columns\n",
        "sns.pairplot(data = df[[ 'PAY_AMT_SEPT', 'PAY_AMT_AUG', 'PAY_AMT_JUL','PAY_AMT_JUN', 'PAY_AMT_MAY', 'PAY_AMT_APR']])"
      ],
      "metadata": {
        "id": "xXrLxKD-x2uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From pairplot 2 we can see that pay amount tends to clutter at one place hence we can try to feature engineer pay amount columns to one payment column to declutter our data."
      ],
      "metadata": {
        "id": "kC3gKELNeJC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking history of PAY_payment\n",
        "pay_col = ['PAY_SEPT',\t'PAY_AUG',\t'PAY_JUL',\t'PAY_JUN',\t'PAY_MAY',\t'PAY_APR']\n",
        "\n",
        "for col in pay_col:\n",
        "    plt.figure(figsize=(16,5))\n",
        "    plt.title(f'Payment records of {col}')\n",
        "    ax=sns.countplot(x = col, hue = 'default payment next month', data = df)\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
      ],
      "metadata": {
        "id": "c7Ivqzlzx2rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From history of past payment it is clear that most people who pay duly are not likely to default their payment"
      ],
      "metadata": {
        "id": "q6SKmxfFzwWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding relation between Age and Limit balance\n",
        "plt.figure(figsize=(15,4))\n",
        "sns.barplot(df['AGE'],df['LIMIT_BAL'])\n",
        "plt.ylabel('Amount of the given credit',fontdict={'fontsize':14})\n",
        "plt.xlabel('Age in years')"
      ],
      "metadata": {
        "id": "Y9X1pH58x2oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can say from age 21 to 39 amount of the given credit is increasing however from 39 to 60 it started to decline."
      ],
      "metadata": {
        "id": "8I29JtI-z58Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Treating Multicollinearity**"
      ],
      "metadata": {
        "id": "RI-T3Reo0Qji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting correlation heatmap\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(df.corr(),annot=True)"
      ],
      "metadata": {
        "id": "P8RQ1lFcx2lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Featuring Engineering**"
      ],
      "metadata": {
        "id": "eYy-0NLI0hbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Payement_Value and Dues columns to treat multicollinearity\n",
        "df_fr = df.copy()\n",
        "df_fr['Payement_Value'] = df_fr['PAY_AMT_SEPT'] + df_fr['PAY_AMT_AUG'] + df_fr['PAY_AMT_JUL'] + df_fr['PAY_AMT_JUN'] + df_fr['PAY_AMT_MAY'] + df_fr['PAY_AMT_APR']\n",
        "\n",
        "df_fr['Dues'] = (df_fr['BILL_AMT_APR']+df_fr['BILL_AMT_MAY']+df_fr['BILL_AMT_JUN']+df_fr['BILL_AMT_JUL']+df_fr['BILL_AMT_SEPT'])-(df_fr['PAY_AMT_APR'])\n",
        "\n",
        "df_fr = df_fr.drop(['ID','BILL_AMT_SEPT',\n",
        "       'BILL_AMT_AUG', 'BILL_AMT_JUL', 'BILL_AMT_JUN', 'BILL_AMT_MAY',\n",
        "       'BILL_AMT_APR', 'PAY_AMT_SEPT', 'PAY_AMT_AUG', 'PAY_AMT_JUL',\n",
        "       'PAY_AMT_JUN', 'PAY_AMT_MAY', 'PAY_AMT_APR'],axis=1)"
      ],
      "metadata": {
        "id": "NfmS0kUbx2iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking the heatmap to find if multicollinearity is reduced\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(df_fr.corr(),annot=True)"
      ],
      "metadata": {
        "id": "c5GLwgctx2fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have tried to treat most of the multi-collinearity using Feature Enginerring."
      ],
      "metadata": {
        "id": "qfPGhwNh0zEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding**"
      ],
      "metadata": {
        "id": "gtZIcfRS03fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding Education and Marriage since both are caategorical variables\n",
        "df_fr = pd.get_dummies(columns = ['EDUCATION','MARRIAGE'], data = df_fr,drop_first=True)\n"
      ],
      "metadata": {
        "id": "SEFqx9Nxx2c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking results of previous execution\n",
        "df_fr.head()"
      ],
      "metadata": {
        "id": "QKgVAOIex2aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr.columns"
      ],
      "metadata": {
        "id": "UEaz3OMCfi_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting The Data**"
      ],
      "metadata": {
        "id": "SAQUsm4h1C4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into dependent and independent variables.Here x=dependent variables and y=dependent variables\n",
        "x = df_fr.drop('default payment next month',axis=1)\n",
        "y = df_fr['default payment next month']\n"
      ],
      "metadata": {
        "id": "BzCtPsjJx2W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the Defaulter and non Defaulter counts for treatment of claass imbalance\n",
        "ax=sns.countplot(y)\n",
        "plt.xticks(rotation=0,ticks=range(2),labels=['Not Defaulter','Is Defaulter'])\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))"
      ],
      "metadata": {
        "id": "xdesro-bx2Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Data Imbalance**"
      ],
      "metadata": {
        "id": "NnmO59Sn1QsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Smote for handling data imbalance\n",
        "SMOTE = SMOTE()\n",
        "X_sm, Y_sm = SMOTE.fit_resample(x,y)\n",
        "\n",
        "# summarize the new class distribution\n",
        "Y_sm.value_counts()"
      ],
      "metadata": {
        "id": "5hRtrcuDx2Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if SMOTE handles the class imbalance\n",
        "ax=sns.countplot(Y_sm)\n",
        "plt.xticks(rotation=0,ticks=range(2),labels=['Not Defaulter','Is Defaulter'])\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))"
      ],
      "metadata": {
        "id": "iw6xJ5gzx2NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scalling**"
      ],
      "metadata": {
        "id": "mV9ohxFS1hXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Scaler for scaling the data\n",
        "scale = StandardScaler()\n",
        "x_std = scale.fit_transform(X_sm)"
      ],
      "metadata": {
        "id": "9uiTPqvYx2KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Test Split**"
      ],
      "metadata": {
        "id": "pynYLDRk1p1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split for splitting the dataset into training and validation sets\n",
        "x_train,x_test,y_train,y_test = model_selection.train_test_split(x_std,Y_sm,test_size=0.2)"
      ],
      "metadata": {
        "id": "P_ZdEQHZx2Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing Models**"
      ],
      "metadata": {
        "id": "fwc5j-p-1-j0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "p87TUIS32FcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Logistic Regression model\n",
        "logistic = LogisticRegression(max_iter=200,random_state=42)\n",
        "logistic.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "QfOWWJTEx2Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = logistic.predict(x_train)\n"
      ],
      "metadata": {
        "id": "a6U9GPswv5e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting using our trained Logistic regression model\n",
        "y_pred_test = logistic.predict(x_test)\n"
      ],
      "metadata": {
        "id": "ZJOza7fOx19z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN test\n",
        "cm = confusion_matrix(y_pred_test,y_test)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "Hp8hP_8Cx16a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics test\n",
        "log_prec=precision_score(y_pred_test,y_test)\n",
        "log_rec=recall_score(y_pred_test,y_test)\n",
        "log_acc=accuracy_score(y_pred_test,y_test)\n",
        "log_f1=f1_score(y_pred_test,y_test)\n",
        "log_roc=roc_auc_score(y_pred_test,y_test)\n",
        "\n",
        "# Printing the classification metrics\n",
        "print('\\033[1mLogistic Regression Classifier Model Metrics test:\\033[0m')\n",
        "print(f\"Precision Score: {log_prec}\\nRecall Score: {log_rec}\\nAccuracy Score: {log_acc}\\nF1 Score: {log_f1}\\nAUC-ROC score: {log_roc}\")"
      ],
      "metadata": {
        "id": "pVuQxgl0x13L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN for train\n",
        "cm = confusion_matrix(y_pred_train,y_train)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "uyF4UHMpytCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics train\n",
        "log_prec=precision_score(y_pred_train,y_train)\n",
        "log_rec=recall_score(y_pred_train,y_train)\n",
        "log_acc=accuracy_score(y_pred_train,y_train)\n",
        "log_f1=f1_score(y_pred_train,y_train)\n",
        "log_roc=roc_auc_score(y_pred_train,y_train)\n",
        "\n",
        "# Printing the classification metrics\n",
        "print('\\033[1mLogistic Regression Classifier Model Metrics train:\\033[0m')\n",
        "print(f\"Precision Score: {log_prec}\\nRecall Score: {log_rec}\\nAccuracy Score: {log_acc}\\nF1 Score: {log_f1}\\nAUC-ROC score: {log_roc}\")"
      ],
      "metadata": {
        "id": "apkssXsvxRIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Classifier**"
      ],
      "metadata": {
        "id": "Xdc0iwVF2bzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Support Vector Classifier Model\n",
        "svc =SVC(random_state=42)\n",
        "svc.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "8yFVJ3XAx1zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting using our trained Support Vector Classifier model\n",
        "y_pred_test = svc.predict(x_test)\n",
        "y_pred_train = svc.predict(x_train)\n"
      ],
      "metadata": {
        "id": "tJnbrrF8x1wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN\n",
        "cm = confusion_matrix(y_pred_test,y_test)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "lnfcN600wnpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics for test\n",
        "svc_prec=precision_score(y_pred_test,y_test)\n",
        "svc_rec=recall_score(y_pred_test,y_test)\n",
        "svc_acc=accuracy_score(y_pred_test,y_test)\n",
        "svc_f1=f1_score(y_pred_test,y_test)\n",
        "svc_roc=roc_auc_score(y_pred_test,y_test)\n",
        "\n",
        "# Printing the classification metrics\n",
        "print('\\033[1mSupport Vector Classifier Model Metrics for test:\\033[0m')\n",
        "print(f\"Precision Score: {svc_prec}\\nRecall Score: {svc_rec}\\nAccuracy Score: {svc_acc}\\nF1 Score: {svc_f1}\\nAUC-ROC score: {svc_roc}\")"
      ],
      "metadata": {
        "id": "4lt2BvWe2YUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN train\n",
        "cm = confusion_matrix(y_pred_train,y_train)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "hNH8bBaW0ITg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics for train\n",
        "svc_prec=precision_score(y_pred_train,y_train)\n",
        "svc_rec=recall_score(y_pred_train,y_train)\n",
        "svc_acc=accuracy_score(y_pred_train,y_train)\n",
        "svc_f1=f1_score(y_pred_train,y_train)\n",
        "svc_roc=roc_auc_score(y_pred_train,y_train)\n",
        "\n",
        "# Printing the classification metrics train\n",
        "print('\\033[1mSupport Vector Classifier Model Metrics for train:\\033[0m')\n",
        "print(f\"Precision Score: {svc_prec}\\nRecall Score: {svc_rec}\\nAccuracy Score: {svc_acc}\\nF1 Score: {svc_f1}\\nAUC-ROC score: {svc_roc}\")"
      ],
      "metadata": {
        "id": "hcQ0rJjHzszC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "k8OtEup9DAZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Decision Tree Classifier Model\n",
        "clf_tree = DecisionTreeClassifier(random_state=42)\n",
        "clf_tree.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "eA1WfQfg2YRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting using our trained Decision Tree Classifier model\n",
        "y_pred_test = clf_tree.predict(x_test)\n",
        "y_pred_train = clf_tree.predict(x_train)"
      ],
      "metadata": {
        "id": "aW3QP3xa2YKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN for test\n",
        "cm = confusion_matrix(y_pred_test,y_test)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "3x73fqgI2YHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics for test\n",
        "dtc_prec=precision_score(y_pred_test,y_test)\n",
        "dtc_rec=recall_score(y_pred_test,y_test)\n",
        "dtc_acc=accuracy_score(y_pred_test,y_test)\n",
        "dtc_f1=f1_score(y_pred_test,y_test)\n",
        "dtc_roc=roc_auc_score(y_pred_test,y_test)\n",
        "\n",
        "# Printing the classification metrics for test\n",
        "print('\\033[1mDecision Tree Classifier Model Metrics test:\\033[0m')\n",
        "print(f\"Precision Score: {dtc_prec}\\nRecall Score: {dtc_rec}\\nAccuracy Score: {dtc_acc}\\nF1 Score: {dtc_f1}\\nAUC-ROC score: {dtc_roc}\")"
      ],
      "metadata": {
        "id": "hbuE8s4j2YD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN for train\n",
        "cm = confusion_matrix(y_pred_train,y_train)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "L_tPdGLf1qVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics for train\n",
        "dtc_prec=precision_score(y_pred_train,y_train)\n",
        "dtc_rec=recall_score(y_pred_train,y_train)\n",
        "dtc_acc=accuracy_score(y_pred_train,y_train)\n",
        "dtc_f1=f1_score(y_pred_train,y_train)\n",
        "dtc_roc=roc_auc_score(y_pred_train,y_train)\n",
        "\n",
        "# Printing the classification metrics for train\n",
        "print('\\033[1mDecision Tree Classifier Model Metrics train:\\033[0m')\n",
        "print(f\"Precision Score: {dtc_prec}\\nRecall Score: {dtc_rec}\\nAccuracy Score: {dtc_acc}\\nF1 Score: {dtc_f1}\\nAUC-ROC score: {dtc_roc}\")"
      ],
      "metadata": {
        "id": "o1D8Mmse1__H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifie**"
      ],
      "metadata": {
        "id": "fvmlVJmrDWdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Random Forest Classifier Model\n",
        "forest = RandomForestClassifier(random_state=42)\n",
        "forest.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "edc-No2a2X-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting using our trained Random Forest Classifier model\n",
        "y_pred_train = forest.predict(x_train)\n",
        "y_pred_train = forest.predict(x_train)"
      ],
      "metadata": {
        "id": "PYayMWwK2X7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN train\n",
        "cm = confusion_matrix(y_pred_train,y_train)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "9sf4U2xt2X3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics\n",
        "rfc_prec=precision_score(y_pred_train,y_train)\n",
        "rfc_rec=recall_score(y_pred_train,y_train)\n",
        "rfc_acc=accuracy_score(y_pred_train,y_train)\n",
        "rfc_f1=f1_score(y_pred_train,y_train)\n",
        "rfc_roc=roc_auc_score(y_pred_train,y_train)\n",
        "\n",
        "# Printing the classification metrics\n",
        "print('\\033[1mRandom Forest Classifier Metrics train:\\033[0m')\n",
        "print(f\"Precision Score: {rfc_prec}\\nRecall Score: {rfc_rec}\\nAccuracy Score: {rfc_acc}\\nF1 Score: {rfc_f1}\\nAUC-ROC score: {rfc_roc}\")"
      ],
      "metadata": {
        "id": "rjcl_Fu-2X1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN train\n",
        "cm = confusion_matrix(y_pred_test,y_test)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "JdgmLB3l3ZF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics\n",
        "rfc_prec=precision_score(y_pred_test,y_test)\n",
        "rfc_rec=recall_score(y_pred_test,y_test)\n",
        "rfc_acc=accuracy_score(y_pred_test,y_test)\n",
        "rfc_f1=f1_score(y_pred_test,y_test)\n",
        "rfc_roc=roc_auc_score(y_pred_test,y_test)\n",
        "\n",
        "# Printing the classification metrics for test\n",
        "print('\\033[1mRandom Forest Classifier Metrics test:\\033[0m')\n",
        "print(f\"Precision Score: {rfc_prec}\\nRecall Score: {rfc_rec}\\nAccuracy Score: {rfc_acc}\\nF1 Score: {rfc_f1}\\nAUC-ROC score: {rfc_roc}\")"
      ],
      "metadata": {
        "id": "lEa5AF2O3sqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost**"
      ],
      "metadata": {
        "id": "x7np0Kk4DwUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Linear Regression Model\n",
        "xgb_clf=xgb.XGBClassifier(max_depth=5,learning_rate=0.3,n_jobs=-1,random_state=42)\n",
        "xgb_clf.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "P_vVoizvDs0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting using our trained Logistic regression model\n",
        "y_pred_test = xgb_clf.predict(x_test)\n",
        "y_pred_train = xgb_clf.predict(x_train)"
      ],
      "metadata": {
        "id": "4Q_QzCEjDswR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN\n",
        "cm = confusion_matrix(y_pred_test,y_test)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "fm0Bws_8Dsra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics for test\n",
        "xgb_prec=precision_score(y_pred_test,y_test)\n",
        "xgb_rec=recall_score(y_pred_test,y_test)\n",
        "xgb_acc=accuracy_score(y_pred_test,y_test)\n",
        "xgb_f1=f1_score(y_pred_test,y_test)\n",
        "xgb_roc=roc_auc_score(y_pred_test,y_test)\n",
        "\n",
        "# Printing the classification metrics for test\n",
        "print('\\033[1mXGboost Model Metrics for test:\\033[0m')\n",
        "print(f\"Precision Score: {xgb_prec}\\nRecall Score: {xgb_rec}\\nAccuracy Score: {xgb_acc}\\nF1 Score: {xgb_f1}\\nAUC-ROC score: {xgb_roc}\")"
      ],
      "metadata": {
        "id": "W96XSoL3Dslo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN for train\n",
        "cm = confusion_matrix(y_pred_train,y_train)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "vnQTw4pm4YOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics for train\n",
        "xgb_prec=precision_score(y_pred_train,y_train)\n",
        "xgb_rec=recall_score(y_pred_train,y_train)\n",
        "xgb_acc=accuracy_score(y_pred_train,y_train)\n",
        "xgb_f1=f1_score(y_pred_train,y_train)\n",
        "xgb_roc=roc_auc_score(y_pred_train,y_train)\n",
        "\n",
        "# Printing the classification metrics for train\n",
        "print('\\033[1mXGboost Model Metrics for train:\\033[0m')\n",
        "print(f\"Precision Score: {xgb_prec}\\nRecall Score: {xgb_rec}\\nAccuracy Score: {xgb_acc}\\nF1 Score: {xgb_f1}\\nAUC-ROC score: {xgb_roc}\")"
      ],
      "metadata": {
        "id": "puvuEZgN4kgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see Decision Tree Classifier, Random forest and Xgboost were performing well on data so we can do hyperparameter tuning on all this data and see which one is performing well in all these three."
      ],
      "metadata": {
        "id": "_5nv89ROnE4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HyperParameter Tuning**"
      ],
      "metadata": {
        "id": "UL8On1hsEG5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "RXOMm6zOFVXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing paramter grid for GridSearchCV\n",
        "parameters = {'min_samples_split':range(1,10),'min_samples_leaf':range(1,10)}\n",
        "\n",
        "# Defining object for GridSearchCV\n",
        "dtc_GCV = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Using GridSearchCV that optimizes scoring parameter precision score\n",
        "dtc_GCV=GridSearchCV(dtc_GCV,parameters,n_jobs=-1,scoring='precision',verbose=10)\n",
        "\n",
        "# Fitting data to our GridSearchCV object \n",
        "dtc_GCV.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "2bxzeF3CFMuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting Using GridSearchCV\n",
        "y_pred = dtc_GCV.predict(x_test)\n"
      ],
      "metadata": {
        "id": "G_jzpF3OFMq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN\n",
        "cm = confusion_matrix(y_pred,y_test)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "UVx0pLCiFMj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics\n",
        "dtc_prec_gcv=precision_score(y_pred,y_test)\n",
        "dtc_rec_gcv=recall_score(y_pred,y_test)\n",
        "dtc_acc_gcv=accuracy_score(y_pred,y_test)\n",
        "dtc_f1_gcv=f1_score(y_pred,y_test)\n",
        "dtc_roc_gcv=roc_auc_score(y_pred,y_test)\n",
        "\n",
        "# Printing the classification metrics\n",
        "print('\\033[1mBest Parameters for Decision Tree Classifier according to GCV:\\033[0m',dtc_GCV.best_params_)\n",
        "print('\\033[1mDecision Tree Classifier Model Metrics:\\033[0m')\n",
        "print(f\"Precision Score: {dtc_prec_gcv}\\nRecall Score: {dtc_rec_gcv}\\nAccuracy Score: {dtc_acc_gcv}\\nF1 Score: {dtc_f1_gcv}\\nAUC-ROC score: {dtc_roc_gcv}\")"
      ],
      "metadata": {
        "id": "W2Ss8MbSFMfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "Vb1szPx3F0zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing paramter grid for GridSearchCV\n",
        "parameters = {'min_samples_split':range(1,10),'min_samples_leaf':range(1,10)}\n",
        "\n",
        "# Defining object for GridSearchCV\n",
        "rfc_GCV = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Using GridSearchCV that optimizes scoring parameter precision score\n",
        "rfc_GCV=GridSearchCV(rfc_GCV,parameters,n_jobs=-1,scoring='precision',verbose=10)\n",
        "\n",
        "# Fitting data to our GridSearchCV object \n",
        "rfc_GCV.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "LmqEl-jXFMbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting Using GridSearchCV\n",
        "y_pred = rfc_GCV.predict(x_test)\n"
      ],
      "metadata": {
        "id": "2HVv5R7UFMXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN\n",
        "cm = confusion_matrix(y_pred,y_test)\n",
        "sns.heatmap(cm, annot=True,fmt='d')"
      ],
      "metadata": {
        "id": "lIdzQ0UV2XyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics\n",
        "rfc_prec_gcv=precision_score(y_pred,y_test)\n",
        "rfc_rec_gcv=recall_score(y_pred,y_test)\n",
        "rfc_acc_gcv=accuracy_score(y_pred,y_test)\n",
        "rfc_f1_gcv=f1_score(y_pred,y_test)\n",
        "rfc_roc_gcv=roc_auc_score(y_pred,y_test)\n",
        "\n",
        "# Printing the classification metrics\n",
        "print('\\033[1mBest Parameters for Decision Tree Classifier according to GCV:\\033[0m',dtc_GCV.best_params_)\n",
        "print('\\033[1mRandom Forest Classifier Model Metrics:\\033[0m')\n",
        "print(f\"Precision Score: {rfc_prec_gcv}\\nRecall Score: {rfc_rec_gcv}\\nAccuracy Score: {rfc_acc_gcv}\\nF1 Score: {rfc_f1_gcv}\\nAUC-ROC score: {rfc_roc_gcv}\")"
      ],
      "metadata": {
        "id": "2SRsKav3GC6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost**"
      ],
      "metadata": {
        "id": "RJ7Gyz0vGLi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing paramter grid for GridSearchCV\n",
        "parameters = {'learning_rate':list(np.linspace(0,1,11))}\n",
        "\n",
        "# Defining object for GridSearchCV\n",
        "xgb_GCV = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Using GridSearchCV that optimizes scoring parameter precision score\n",
        "xgb_GCV=GridSearchCV(xgb_GCV,parameters,n_jobs=-1,scoring='precision',verbose=10)\n",
        "\n",
        "# Fitting data to our GridSearchCV object \n",
        "xgb_GCV.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "u--zFRK3GC2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting Using GridSearchCV\n",
        "y_pred = xgb_GCV.predict(x_test)\n"
      ],
      "metadata": {
        "id": "Yec91MskGCzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating confusion matrix to check TP,FP,FN,TN\n",
        "cm = confusion_matrix(y_pred,y_test)\n",
        "sns.heatmap(cm, annot=True,fmt='d', cmap=\"Blues\")"
      ],
      "metadata": {
        "id": "9gyML0TPGCvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification metrics\n",
        "xgb_prec_gcv=precision_score(y_pred,y_test)\n",
        "xgb_rec_gcv=recall_score(y_pred,y_test)\n",
        "xgb_acc_gcv=accuracy_score(y_pred,y_test)\n",
        "xgb_f1_gcv=f1_score(y_pred,y_test)\n",
        "xgb_roc_gcv=roc_auc_score(y_pred,y_test)\n",
        "\n",
        "# Printing the classification metrics\n",
        "print('\\033[1mBest Parameters for XGBoost Classifier according to GCV:\\033[0m',xgb_GCV.best_params_)\n",
        "print('\\033[1mXGBoost Classifier Model Metrics:\\033[0m')\n",
        "print(f\"Precision Score: {xgb_prec_gcv}\\nRecall Score: {xgb_rec_gcv}\\nAccuracy Score: {xgb_acc_gcv}\\nF1 Score: {xgb_f1_gcv}\\nAUC-ROC score: {xgb_roc_gcv}\")"
      ],
      "metadata": {
        "id": "wEMHtfwhGCrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw Random forest classifier is best fitted among all the classifiers between data."
      ],
      "metadata": {
        "id": "xezUYONGqCtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results=cross_validate(rfc_GCV.best_estimator_,x_train,y_train,scoring='accuracy',cv=3,n_jobs=-1)\n",
        "print(cv_results)"
      ],
      "metadata": {
        "id": "lQwlQeWSGCTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('''\\033[1mThe Performance of our best model :{}\n",
        "with GridSearch parameters: {}\n",
        "according to cross validate method of sklearn:\\033[0m'''.format(rfc_GCV.best_estimator_,rfc_GCV.best_params_))\n",
        "print('The average time for fitting the estimator on the train set is {}'.format(round((cv_results['fit_time'].sum())/len(cv_results['fit_time']),5)))\n",
        "print('The average time for scoring the estimator on the test set is {}'.format(round((cv_results['score_time'].sum())/len(cv_results['score_time']),5)))\n",
        "print('The average Accuracy for Estimator is {}'.format(round((cv_results['test_score'].sum())/len(cv_results['test_score']),5)))"
      ],
      "metadata": {
        "id": "u8m-Bba_GCPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Findings From Eda**\n",
        "\n",
        "1. The number of people who will default their payment is much less than number of people of people who will pay on time\n",
        "\n",
        "2. The Number of females are much more than males in our dataset (6,224) and we can also say that females tend to pay their default on time compared to their male counterparts\n",
        "\n",
        "3. Married people are more likely to pay their default payments compared to singles and others\n",
        "\n",
        "4. We can also say that Singles do not pay their default payment marginally as compared to married counterparts\n",
        "\n",
        "5. From pairplot 1 Bill amount for each month is highly correlated with each other hence we will try to feature engineer bill amount to Dues column to reduce multicollinearity\n",
        "\n",
        "6. From pairplot 2 we can see that pay amount tends to clutter at one place hence we can try to feature engineer pay amount columns to one payment column to declutter our data\n",
        "\n",
        "7. From history of past payment analysis it is clear that most people who pay duly are not likely to default their payment\n",
        "\n",
        "8. Here, we can say from age 21 to 39 limit balance is increasing however from 39 to 60 it started to decline."
      ],
      "metadata": {
        "id": "Jvf_S3FtugG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Conclusion-----------***\n",
        "1. In our dataset, We used many algorithm like Logistic Regression,Support vector classsifier,decision tree classifier,XGBoost Classifier,Random Forest Classifier.\n",
        "2. Random Forest was the best performing algorithm as shown below\n",
        "\n",
        "1. Random Forest Classifier has the best value of accuracy score of 84%\n",
        "2. Random Forest Classifier has the best value of precision score of 84%\n",
        "3. Random Forest Classifier has the best value of recall score of 83%\n",
        "4. Random Forest Classifier has the best value of f1 score of 84%\n",
        "5. Random Forest Classifier has the best value of Roc_auc score of 84%\n",
        "6. This proves Random Forest Classifier algorithm has perfectly fitted all the dataset"
      ],
      "metadata": {
        "id": "Yw6NSfBTHYoq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPURF0BuGCLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MK4LwU2n2XvP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}